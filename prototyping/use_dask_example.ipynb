{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading refseq and reaction tables...\n",
      "Reference sequences in this file: /project/projectdirs/metatlas/projects/metatlas_reactions/workflow/database/mrs_reaction_filtered_refseq_db_newrxns_actinofixed.pkl\n",
      "135905 reference sequences\n",
      "MRS-Reaction: /project/projectdirs/metatlas/projects/metatlas_reactions/workflow/database/mrs_reaction_newrxns_added_actinofix.pkl\n",
      "16966 reactions\n",
      "10368 reactions with a refseq\n",
      "9363 reactions with an EC\n",
      "loading compound table\n",
      "loading chemnet files\n",
      "All databases loaded into memory\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "fasta = \"/global/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/magi/cdhitout.faa\"\n",
    "compounds = \"/global/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/Pactolus_Results_20160824_KBL_SolarPanel_MP/pactolus_hits.csv\"\n",
    "gene_to_reaction = \"/global/project/projectdirs/openmsi/projects/temp_chem_net_data/MAGI_data/cdhitout_20170531/gene_to_reaction.pkl\"\n",
    "output = \"/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/magi_lipid_posneg\"\n",
    "reaction_to_gene = \"/global/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/magi_lipid_posneg/reaction_to_gene.pkl\"\n",
    "compound_to_reaction = \"/global/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/magi_lipid_posneg/compound_to_reaction.pkl\"\n",
    "\n",
    "max_cpu = mp.cpu_count()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load local settings\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    '/project/projectdirs/metatlas/projects/metatlas_reactions/')\n",
    "from local_settings import local_settings as settings_loc\n",
    "my_settings = getattr(\n",
    "    __import__(\n",
    "        'local_settings',\n",
    "        fromlist=[settings_loc.SETTINGS_FILE]), settings_loc.SETTINGS_FILE)\n",
    "\n",
    "# import workflow helpers after all the argument checking\n",
    "sys.path.insert(\n",
    "    0,\n",
    "    os.path.join(my_settings.repo_location, 'workflow/helpertools'))\n",
    "import workflow_helpers as mg\n",
    "\n",
    "# path to MAGI data storage\n",
    "MAGI_PATH = my_settings.magi_results_storage\n",
    "experiment_path = output\n",
    "if not os.path.isdir(experiment_path):\n",
    "    os.makedirs(experiment_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804258 genes\n",
      "saved gene_sequence table here: /global/project/projectdirs/openmsi/projects/temp_chem_net_data/MAGI_data/gene_fastas/cdhitout_sequences.pkl\n",
      "blast database stored here: /global/project/projectdirs/openmsi/projects/temp_chem_net_data/MAGI_data/BLAST_dbs/cdhitout.db\n"
     ]
    }
   ],
   "source": [
    "# load genome\n",
    "genome, genome_db_path = mg.load_genome(fasta, MAGI_PATH, annotation_file=None)\n",
    "\n",
    "# load pactolus results\n",
    "compounds = mg.load_dataframe(compounds)\n",
    "# auto-rename pactolus columns\n",
    "# if pactolus:\n",
    "#     compounds = mg.reformat_pactolus(compounds)\n",
    "# remove any missing compounds\n",
    "compounds = compounds[~pd.isnull(compounds['original_compound'])]\n",
    "compounds.fillna('', inplace=True)\n",
    "\n",
    "u_cpds = compounds['original_compound'].unique()\n",
    "compounds['compound_score'] = compounds['compound_score'].apply(float)\n",
    "gene_to_reaction_top = pd.read_pickle(gene_to_reaction)\n",
    "compound_to_reaction = pd.read_pickle(compound_to_reaction)\n",
    "reaction_to_gene_top = pd.read_pickle(reaction_to_gene)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove any compounds that don't have a reaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'spectrum_index', u'polarity', u'precursor intensity',\n",
       "       u'precursor_mz', u'retention_time', u'filename_x', u'compound_score',\n",
       "       u'compound', u'compound_index', u'filename_y', u'inchi',\n",
       "       u'original_compound', u'ms1_mass', u'permanent_charge',\n",
       "       u'mono_isotopic_molecular_weight', u'creation_time', u'synonyms',\n",
       "       u'neutralized_2d_inchi_key', u'chebi_url', u'img_abc_id',\n",
       "       u'neutralized_2d_inchi', u'lipidmaps_url', u'source', u'kegg_url',\n",
       "       u'hmdb_url', u'wikipedia_url', u'formula', u'number_components',\n",
       "       u'iupac_name', u'username', u'pubchem_compound_id', u'description',\n",
       "       u'metacyc_id', u'kegg_id', u'hmdb_id', u'chebi_id',\n",
       "       u'neutralized_inchi_key', u'neutralized_inchi', u'name',\n",
       "       u'num_free_radicals', u'lipidmaps_id', u'last_modified', u'pubchem_url',\n",
       "       u'unique_id', u'detected_polarity', u'ppm', u'level', u'neighbor',\n",
       "       u'note', u'reaction_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compound_to_reaction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6903869, 51)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print compound_to_reaction.shape\n",
    "idx1 = compound_to_reaction.level == 0\n",
    "idx2 = compound_to_reaction.reaction_id != ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179366, 51)\n"
     ]
    }
   ],
   "source": [
    "compound_to_reaction = compound_to_reaction[(idx1 & idx2)]\n",
    "print compound_to_reaction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 s, sys: 4.18 s, total: 23.2 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from dask import dataframe as dd\n",
    "import dask.dataframe as dd\n",
    "#Construct a dask objects from a pandas objects\n",
    "left1 = dd.from_pandas(compound_to_reaction, npartitions=8)\n",
    "right1 = dd.from_pandas(reaction_to_gene_top, npartitions=4)\n",
    "\n",
    "#merge on key\n",
    "compound_to_gene = dd.merge(left1, right1, on='reaction_id', how='left').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compound_to_gene_small = compound_to_gene[['subject acc.', 'reaction_id',\n",
    "                            'e_score', 'compound_score',\n",
    "                            'original_compound', 'level', 'neighbor',\n",
    "                            'note']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# okay to drop duplicates, because i only care about these columns \n",
    "# anyway; if these are duplicated then other information doesn't really \n",
    "# matter or can easily be re-expanded by joining \n",
    "compound_to_gene_small.drop_duplicates(inplace=True)\n",
    "\n",
    "gene_to_reaction_small = gene_to_reaction_top[['query acc.', 'reaction_id',\n",
    "                                                'e_score']]\n",
    "gene_to_reaction_small.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del reaction_to_gene_top\n",
    "del compound_to_reaction\n",
    "del compound_to_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.3 s, sys: 5.44 s, total: 28.8 s\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# from dask import dataframe as dd\n",
    "import dask.dataframe as dd\n",
    "#Construct a dask objects from a pandas objects\n",
    "left1 = dd.from_pandas(compound_to_gene_small, npartitions=8)\n",
    "right1 = dd.from_pandas(gene_to_reaction_small, npartitions=8)\n",
    "\n",
    "\n",
    "# Make an integrated dataframe, joining on the gene\n",
    "df = dd.merge(left1, right1, \n",
    "    left_on='subject acc.', right_on='query acc.', \n",
    "    suffixes=('_r2g', '_g2r'), how='outer').compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del left1\n",
    "del right1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #think about saving df here\n",
    "# df.to_hdf('/project/projectdirs/metatlas/projects/jgi_projects/SolarPanel/df_magi_save.h5',\n",
    "#     'merged_before_score', mode='w', format='table',\n",
    "#     complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 Âµs, sys: 12 ms, total: 13 ms\n",
      "Wall time: 12.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #should take about 35 minutes to make the dask dataframe\n",
    "# #partitions: 1 = 52\n",
    "# #partitions: 4 = 1min 55 s\n",
    "# # df.drop_duplicates(inplace=True)\n",
    "# print df.shape\n",
    "# ddf = dd.from_pandas(df.head(2000000), npartitions=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df2 = ddf.drop_duplicates().compute()\n",
    "\n",
    "# print df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.33 s, sys: 475 ms, total: 5.8 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean up reaction_id_r2g column\n",
    "df.reaction_id_r2g = df.reaction_id_r2g.replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22008772, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 119 ms, sys: 98 ms, total: 217 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['reaction_id_r2g'] = df['reaction_id_r2g'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject acc.\n",
      "subject acc. is too many\n",
      "reaction_id_r2g\n",
      "e_score_r2g\n",
      "compound_score\n",
      "original_compound\n",
      "original_compound is too many\n",
      "level\n",
      "neighbor\n",
      "neighbor is too many\n",
      "note\n",
      "note is too many\n",
      "query acc.\n",
      "query acc. is too many\n",
      "reaction_id_g2r\n",
      "e_score_g2r\n",
      "CPU times: user 1min 10s, sys: 2.17 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Clean up NaNs in string columns that make column object type\n",
    "def check_str(x):\n",
    "    if isinstance(x, str):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "for c in df.columns:\n",
    "    print c\n",
    "    if len(df[c].apply(type).unique()) > 1:\n",
    "        print c,'is too many'\n",
    "        string_checked = df[c].apply(check_str)\n",
    "        if string_checked.any():\n",
    "            df[c].fillna('', inplace=True)\n",
    "\n",
    "# Clean up neighbor column\n",
    "df['neighbor'] = df['neighbor'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 8.67 s, total: 28.6 s\n",
      "Wall time: 28.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# score reciprocal agreement\n",
    "df = mg.reciprocal_agreement(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 275 ms, sys: 259 ms, total: 534 ms\n",
      "Wall time: 548 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# calculate homology score\n",
    "score = mg.homology_score(df)\n",
    "# the nulls get a really low score\n",
    "score[pd.isnull(score)] = 1\n",
    "df['homology_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 ms, sys: 246 ms, total: 362 ms\n",
      "Wall time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# adjust compound score slightly by leveled search\n",
    "df['level_adjusted_compound_score'] = df['compound_score'].values / \\\n",
    "                                            (df['level'].values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reaction connection score says if the compound got connected to any\n",
    "# reaction in the database. Can't have zero because that messes up\n",
    "# geometric mean, so added a small number.\n",
    "df['reaction_connection'] = df[['reaction_id_r2g', 'reaction_id_g2r']]\\\n",
    "                                .apply(pd.notnull).sum(axis=1) + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate final MAGI integrated score\n",
    "scoring_data = ['level_adjusted_compound_score', 'reciprocal_score', \\\n",
    "                'homology_score', 'reaction_connection']\n",
    "scores = []\n",
    "to_score = df[scoring_data].values\n",
    "data = []\n",
    "for s in to_score:\n",
    "    data.append(mg.magi_score(s, weights=None))\n",
    "scores.append(data)\n",
    "df['MAGI_score'] = scores[0] / (4. ** df['level'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find gene ids that are floats, convert those to strings, without the decimal\n",
    "float_entries = df['subject acc.'].apply(lambda x: isinstance(x, float))\n",
    "df.loc[float_entries, 'subject acc.'] = df.loc[float_entries, \\\n",
    "                'subject acc.'].apply(lambda x: \"{:.0f}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort the final table and drop key duplicates\n",
    "df = df.sort_values(\n",
    "    ['original_compound', 'MAGI_score'], \n",
    "    ascending=[True, False]\n",
    "    ).drop_duplicates(\n",
    "        ['original_compound', 'level', 'neighbor', 'compound_score',\n",
    "         'reciprocal_score', 'query acc.', 'reaction_id_r2g',\n",
    "         'reaction_id_g2r']\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_hdf(os.path.join(experiment_path, 'merged_with_score.h5'),\n",
    "    'merged_with_score', mode='w', format='table',\n",
    "    complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the full dataframe\n",
    "df.to_csv(os.path.join(experiment_path, 'magi_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save a compound-centric dataframe, where only the best row for each\n",
    "# original_compound was chosen (this is only for compound scoring, do\n",
    "# not use this for any kind of gene function analysis!)\n",
    "compound_centric = df[pd.notnull(df['original_compound'])]\\\n",
    "                     .sort_values('MAGI_score', ascending=False)\\\n",
    "                     .drop_duplicates(['original_compound', 'compound_score'])\n",
    "compound_centric = pd.merge(\n",
    "    compound_centric, compounds,\n",
    "    on=['original_compound', 'compound_score'],\n",
    "    how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compound_centric.to_csv(os.path.join(experiment_path, \n",
    "    'magi_compound_results.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Show taxonomic groups as rows and compounds as columns. Cluster the taxonomic groups and compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "MetAtlas 2.7",
   "language": "python",
   "name": "metatlas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
